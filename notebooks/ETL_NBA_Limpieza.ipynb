{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d53d050",
   "metadata": {},
   "source": [
    "# ETL NBA Limpieza - Proyecto Daft17_Group01_PF (Versión 2)\n",
    "Este notebook procesa los datasets crudos de la NBA, normalizando nombres, fechas, años, nulos, duplicados semánticos y ahora corrigiendo altura y peso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c0d4f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ game.csv cargado correctamente (65698 filas, 55 columnas)\n",
      "✅ game_summary.csv cargado correctamente (58110 filas, 14 columnas)\n",
      "✅ other_stats.csv cargado correctamente (28271 filas, 26 columnas)\n",
      "✅ player.csv cargado correctamente (4831 filas, 5 columnas)\n",
      "✅ common_player_info.csv cargado correctamente (4171 filas, 33 columnas)\n",
      "✅ team.csv cargado correctamente (30 filas, 7 columnas)\n",
      "📘 Columnas normalizadas en game: 55 columnas\n",
      "📘 Columnas normalizadas en game_summary: 14 columnas\n",
      "📘 Columnas normalizadas en other_stats: 26 columnas\n",
      "📘 Columnas normalizadas en player: 5 columnas\n",
      "📘 Columnas normalizadas en common_player_info: 33 columnas\n",
      "📘 Columnas normalizadas en team: 7 columnas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juanl\\AppData\\Local\\Temp\\ipykernel_10084\\2433312825.py:72: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df[col] = pd.to_datetime(df[col], errors=\"coerce\", infer_datetime_format=True)\n",
      "C:\\Users\\juanl\\AppData\\Local\\Temp\\ipykernel_10084\\2433312825.py:72: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df[col] = pd.to_datetime(df[col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📅 Años y fechas corregidos en game\n",
      "📅 Años y fechas corregidos en game_summary\n",
      "📅 Años y fechas corregidos en other_stats\n",
      "📅 Años y fechas corregidos en player\n",
      "📅 Años y fechas corregidos en common_player_info\n",
      "📅 Años y fechas corregidos en team\n",
      "🏋️‍♂️ Altura y peso corregidos en common_player_info\n",
      "⚠️ Posibles duplicadas en game:\n",
      "   - fgm_home ≈ fg3m_home (94% similitud)\n",
      "   - fga_home ≈ fg3a_home (94% similitud)\n",
      "   - fg_pct_home ≈ fg3_pct_home (96% similitud)\n",
      "   - fg_pct_home ≈ ft_pct_home (91% similitud)\n",
      "   - oreb_home ≈ reb_home (94% similitud)\n",
      "   - dreb_home ≈ reb_home (94% similitud)\n",
      "   - fgm_away ≈ fg3m_away (94% similitud)\n",
      "   - fga_away ≈ fg3a_away (94% similitud)\n",
      "   - fg_pct_away ≈ fg3_pct_away (96% similitud)\n",
      "   - fg_pct_away ≈ ft_pct_away (91% similitud)\n",
      "   - oreb_away ≈ reb_away (94% similitud)\n",
      "   - dreb_away ≈ reb_away (94% similitud)\n",
      "✅ game_summary: sin columnas duplicadas evidentes.\n",
      "✅ other_stats: sin columnas duplicadas evidentes.\n",
      "✅ player: sin columnas duplicadas evidentes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juanl\\AppData\\Local\\Temp\\ipykernel_10084\\2433312825.py:72: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df[col] = pd.to_datetime(df[col], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Posibles duplicadas en common_player_info:\n",
      "   - display_first_last ≈ display_fi_last (91% similitud)\n",
      "✅ team: sin columnas duplicadas evidentes.\n",
      "🧽 Nulos limpiados en game: 65698 filas, 55 columnas\n",
      "🧽 Nulos limpiados en game_summary: 58110 filas, 14 columnas\n",
      "🧽 Nulos limpiados en other_stats: 28271 filas, 26 columnas\n",
      "🧽 Nulos limpiados en player: 4831 filas, 5 columnas\n",
      "🧽 Nulos limpiados en common_player_info: 4171 filas, 33 columnas\n",
      "🧽 Nulos limpiados en team: 30 filas, 7 columnas\n",
      "✅ game guardado en: C:\\Users\\juanl\\Downloads\\final\\csv\\game_clean.csv\n",
      "✅ game_summary guardado en: C:\\Users\\juanl\\Downloads\\final\\csv\\game_summary_clean.csv\n",
      "✅ other_stats guardado en: C:\\Users\\juanl\\Downloads\\final\\csv\\other_stats_clean.csv\n",
      "✅ player guardado en: C:\\Users\\juanl\\Downloads\\final\\csv\\player_clean.csv\n",
      "✅ common_player_info guardado en: C:\\Users\\juanl\\Downloads\\final\\csv\\common_player_info_clean.csv\n",
      "✅ team guardado en: C:\\Users\\juanl\\Downloads\\final\\csv\\team_clean.csv\n",
      "\n",
      "📋 Resumen general de los datasets:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Filas</th>\n",
       "      <th>Columnas</th>\n",
       "      <th>Porc_nulos_prom</th>\n",
       "      <th>Numéricas</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Fechas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>game</td>\n",
       "      <td>65698</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>game_summary</td>\n",
       "      <td>58110</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>other_stats</td>\n",
       "      <td>28271</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>player</td>\n",
       "      <td>4831</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>common_player_info</td>\n",
       "      <td>4171</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>team</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dataset  Filas  Columnas  Porc_nulos_prom  Numéricas  Texto  \\\n",
       "0                game  65698        54              0.0         45      8   \n",
       "1        game_summary  58110        12              0.0          8      3   \n",
       "2         other_stats  28271        26              0.0         22      4   \n",
       "3              player   4831         5              0.0          2      3   \n",
       "4  common_player_info   4171        32              0.0          7     24   \n",
       "5                team     30         7              0.0          2      5   \n",
       "\n",
       "   Fechas  \n",
       "0       1  \n",
       "1       1  \n",
       "2       0  \n",
       "3       0  \n",
       "4       1  \n",
       "5       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ==========================================================\n",
    "# BLOQUE 1: IMPORTACIÓN Y CONFIGURACIÓN INICIAL\n",
    "# ==========================================================\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "path_raw = r\"C:\\Users\\juanl\\Downloads\\final\\csv\\Daft17_Group01_PF\\data\\raw\"\n",
    "path_final = r\"C:\\Users\\juanl\\Downloads\\final\\csv\"\n",
    "\n",
    "input_files = {\n",
    "    \"game\": \"game.csv\",\n",
    "    \"game_summary\": \"game_summary.csv\",\n",
    "    \"other_stats\": \"other_stats.csv\",\n",
    "    \"player\": \"player.csv\",\n",
    "    \"common_player_info\": \"common_player_info.csv\",\n",
    "    \"team\": \"team.csv\"\n",
    "}\n",
    "\n",
    "dataframes = {}\n",
    "for name, file in input_files.items():\n",
    "    try:\n",
    "        full_path = os.path.join(path_raw, file)\n",
    "        df = pd.read_csv(full_path, low_memory=False)\n",
    "        dataframes[name] = df\n",
    "        print(f\"✅ {file} cargado correctamente ({df.shape[0]} filas, {df.shape[1]} columnas)\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error cargando {file}: {e}\")\n",
    "\n",
    "# ==========================================================\n",
    "# BLOQUE 2: NORMALIZACIÓN DE NOMBRES DE COLUMNAS\n",
    "# ==========================================================\n",
    "def limpiar_nombre_columna(nombre):\n",
    "    nombre = unicodedata.normalize(\"NFKC\", str(nombre))\n",
    "    nombre = nombre.strip().lower()\n",
    "    nombre = re.sub(r\"[áàäâ]\", \"a\", nombre)\n",
    "    nombre = re.sub(r\"[éèëê]\", \"e\", nombre)\n",
    "    nombre = re.sub(r\"[íìïî]\", \"i\", nombre)\n",
    "    nombre = re.sub(r\"[óòöô]\", \"o\", nombre)\n",
    "    nombre = re.sub(r\"[úùüû]\", \"u\", nombre)\n",
    "    nombre = re.sub(r\"[^a-z0-9]+\", \"_\", nombre)\n",
    "    return nombre.strip(\"_\")\n",
    "\n",
    "def normalizar_columnas(df):\n",
    "    df.columns = [limpiar_nombre_columna(c) for c in df.columns]\n",
    "    return df\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    dataframes[name] = normalizar_columnas(df)\n",
    "    print(f\"📘 Columnas normalizadas en {name}: {len(df.columns)} columnas\")\n",
    "\n",
    "# ==========================================================\n",
    "# BLOQUE 3: CORRECCIÓN DE FECHAS Y AÑOS\n",
    "# ==========================================================\n",
    "def truncar_anio(valor):\n",
    "    try:\n",
    "        val = str(int(float(valor)))\n",
    "        if len(val) > 4:\n",
    "            return int(val[:4])\n",
    "        return int(val)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def corregir_anios_y_fechas(df):\n",
    "    for col in df.columns:\n",
    "        if \"year\" in col or \"anio\" in col or \"season\" in col:\n",
    "            df[col] = df[col].apply(truncar_anio).astype(\"Int64\")\n",
    "        if \"date\" in col or \"fecha\" in col:\n",
    "            df[col] = pd.to_datetime(df[col], errors=\"coerce\", infer_datetime_format=True)\n",
    "    return df\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    dataframes[name] = corregir_anios_y_fechas(df)\n",
    "    print(f\"📅 Años y fechas corregidos en {name}\")\n",
    "\n",
    "# ==========================================================\n",
    "# BLOQUE 3.1: CORRECCIÓN DE ALTURA Y PESO (AJUSTADO)\n",
    "# ==========================================================\n",
    "# - Altura: reemplaza \"-\" por \",\" en columnas tipo \"height\" o \"altura\"\n",
    "# - Peso: divide por 10 los valores sospechosamente grandes (>400)\n",
    "# ==========================================================\n",
    "\n",
    "# ==========================================================\n",
    "# BLOQUE 3.1: CORRECCIÓN DE ALTURA Y PESO (FINAL)\n",
    "# ==========================================================\n",
    "# - Altura: reemplaza \"-\" por \",\" en columnas tipo \"height\" o \"altura\"\n",
    "# - Peso: divide SIEMPRE todos los valores por 10\n",
    "# ==========================================================\n",
    "\n",
    "def corregir_altura_peso(df):\n",
    "    for col in df.columns:\n",
    "        # Altura: reemplazar guiones por comas\n",
    "        if \"height\" in col or \"altura\" in col:\n",
    "            df[col] = df[col].astype(str).str.replace(\"-\", \",\", regex=False)\n",
    "\n",
    "        # Peso: convertir y dividir todos los valores por 10\n",
    "        if \"weight\" in col or \"peso\" in col:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\") / 10\n",
    "\n",
    "    return df\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    if any(\"height\" in c or \"peso\" in c or \"weight\" in c or \"altura\" in c for c in df.columns):\n",
    "        dataframes[name] = corregir_altura_peso(df)\n",
    "        print(f\"🏋️‍♂️ Altura y peso corregidos en {name}\")\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# BLOQUE 4: DETECCIÓN DE COLUMNAS DUPLICADAS O SIMILARES\n",
    "# ==========================================================\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def columnas_similares(df, threshold=0.9):\n",
    "    cols = df.columns\n",
    "    similares = []\n",
    "    for i in range(len(cols)):\n",
    "        for j in range(i+1, len(cols)):\n",
    "            ratio = SequenceMatcher(None, cols[i], cols[j]).ratio()\n",
    "            if ratio >= threshold:\n",
    "                similares.append((cols[i], cols[j], round(ratio,2)))\n",
    "    return similares\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    similares = columnas_similares(df)\n",
    "    if similares:\n",
    "        print(f\"⚠️ Posibles duplicadas en {name}:\")\n",
    "        for c1, c2, r in similares:\n",
    "            print(f\"   - {c1} ≈ {c2} ({r*100:.0f}% similitud)\")\n",
    "    else:\n",
    "        print(f\"✅ {name}: sin columnas duplicadas evidentes.\")\n",
    "\n",
    "# ==========================================================\n",
    "# BLOQUE 5: LIMPIEZA DE NULOS\n",
    "# ==========================================================\n",
    "def limpiar_nulos(df):\n",
    "    df = df.loc[:, df.isna().mean() < 0.8]\n",
    "    id_cols = [c for c in df.columns if 'id' in c]\n",
    "    if id_cols:\n",
    "        df = df.dropna(subset=id_cols)\n",
    "    num_cols = df.select_dtypes(include='number').columns\n",
    "    for col in num_cols:\n",
    "        if df[col].isna().mean() > 0:\n",
    "            df[col] = df[col].fillna(df[col].median() if df[col].isna().mean() < 0.3 else 0)\n",
    "    cat_cols = df.select_dtypes(include='object').columns\n",
    "    for col in cat_cols:\n",
    "        df[col] = df[col].fillna('Desconocido')\n",
    "    return df\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    dataframes[name] = limpiar_nulos(df)\n",
    "    print(f\"🧽 Nulos limpiados en {name}: {df.shape[0]} filas, {df.shape[1]} columnas\")\n",
    "\n",
    "# ==========================================================\n",
    "# BLOQUE 6: EXPORTACIÓN DE ARCHIVOS LIMPIOS\n",
    "# ==========================================================\n",
    "os.makedirs(path_final, exist_ok=True)\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    out_path = os.path.join(path_final, f\"{name}_clean.csv\")\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"✅ {name} guardado en: {out_path}\")\n",
    "\n",
    "# ==========================================================\n",
    "# BLOQUE 7: REPORTE DE CALIDAD DE DATOS\n",
    "# ==========================================================\n",
    "resumen = []\n",
    "for name, df in dataframes.items():\n",
    "    resumen.append({\n",
    "        \"Dataset\": name,\n",
    "        \"Filas\": len(df),\n",
    "        \"Columnas\": len(df.columns),\n",
    "        \"Porc_nulos_prom\": round(df.isna().mean().mean()*100, 2),\n",
    "        \"Numéricas\": len(df.select_dtypes(include='number').columns),\n",
    "        \"Texto\": len(df.select_dtypes(include='object').columns),\n",
    "        \"Fechas\": sum(\"datetime\" in str(t) for t in df.dtypes)\n",
    "    })\n",
    "\n",
    "reporte_df = pd.DataFrame(resumen)\n",
    "print(\"\\n📋 Resumen general de los datasets:\")\n",
    "display(reporte_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

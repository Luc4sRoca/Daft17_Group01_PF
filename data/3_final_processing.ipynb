{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: FINAL processing with automated ingestion and validations\n",
      "Loaded player_final.csv with shape (4831, 5)\n",
      "Loaded team_final.csv with shape (30, 7)\n",
      "Loaded game_final.csv with shape (65642, 55)\n",
      "Loaded game_summary_final.csv with shape (58021, 14)\n",
      "Loaded other_stats_final.csv with shape (28261, 26)\n",
      "dim_team PK team_id: False. PK columns missing: {'team_id'}\n",
      "dim_player PK player_id: False. PK columns missing: {'player_id'}\n",
      "fact_game PK game_id: True. Duplicate rows by PK: 0\n",
      "FK fact_player_game.game_id -> fact_game.game_id: True. Unmatched rows: 0\n",
      "FK fact_player_game.player_id -> dim_player.player_id: False. Columns not found: player_id or player_id\n",
      "Ingestion changes detected since last run:\n",
      "stats: -10 rows vs previous run\n",
      "Saved ingestion status snapshot to c:\\Users\\juanl\\Downloads\\final\\csv\\Daft17_Group01_PF\\data\\data_status.csv\n",
      "Wrote SQL DDL to c:\\Users\\juanl\\Downloads\\final\\csv\\Daft17_Group01_PF\\data\\nba_schema_sqlserver.sql\n",
      "Completed FINAL processing in 0.82 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, time, json, pandas as pd, numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def validate_pk(df, cols):\n",
    "    if not all(c in df.columns for c in cols):\n",
    "        return False, f\"PK columns missing: {set(cols)-set(df.columns)}\"\n",
    "    dups = df.duplicated(subset=cols).sum()\n",
    "    return dups == 0, f\"Duplicate rows by PK: {dups}\"\n",
    "\n",
    "def validate_fk(df_from, col_from, df_to, col_to):\n",
    "    if col_from not in df_from.columns or col_to not in df_to.columns:\n",
    "        return False, f\"Columns not found: {col_from} or {col_to}\"\n",
    "    missing = ~df_from[col_from].isin(df_to[col_to])\n",
    "    return missing.sum() == 0, f\"Unmatched rows: {missing.sum()}\"\n",
    "\n",
    "start = time.time()\n",
    "print(\"Start: FINAL processing with automated ingestion and validations\")\n",
    "\n",
    "cwd = os.getcwd()\n",
    "files = {\n",
    "    \"player\": \"player_final.csv\",\n",
    "    \"team\": \"team_final.csv\",\n",
    "    \"game\": \"game_final.csv\",\n",
    "    \"summary\": \"game_summary_final.csv\",\n",
    "    \"stats\": \"other_stats_final.csv\"\n",
    "}\n",
    "dfs = {}\n",
    "for k, fname in files.items():\n",
    "    p = os.path.join(cwd, fname)\n",
    "    if os.path.exists(p):\n",
    "        dfs[k] = pd.read_csv(p, low_memory=False)\n",
    "        print(f\"Loaded {fname} with shape {dfs[k].shape}\")\n",
    "    else:\n",
    "        print(f\"Warning: {fname} not found\")\n",
    "\n",
    "player = dfs.get(\"player\", pd.DataFrame())\n",
    "team = dfs.get(\"team\", pd.DataFrame())\n",
    "game = dfs.get(\"game\", pd.DataFrame())\n",
    "summary = dfs.get(\"summary\", pd.DataFrame())\n",
    "stats = dfs.get(\"stats\", pd.DataFrame())\n",
    "\n",
    "# PK checks\n",
    "if not team.empty:\n",
    "    ok, msg = validate_pk(team, [\"team_id\"]); print(f\"dim_team PK team_id: {ok}. {msg}\")\n",
    "if not player.empty:\n",
    "    ok, msg = validate_pk(player, [\"player_id\"]); print(f\"dim_player PK player_id: {ok}. {msg}\")\n",
    "if not game.empty:\n",
    "    ok, msg = validate_pk(game, [\"game_id\"]); print(f\"fact_game PK game_id: {ok}. {msg}\")\n",
    "if not stats.empty and all(c in stats.columns for c in [\"game_id\",\"player_id\"]):\n",
    "    ok, msg = validate_pk(stats, [\"game_id\",\"player_id\"]); print(f\"fact_player_game PK (game_id, player_id): {ok}. {msg}\")\n",
    "\n",
    "# FK checks\n",
    "if not game.empty and not team.empty and \"team_id\" in team.columns:\n",
    "    for col in [\"home_team_id\",\"visitor_team_id\"]:\n",
    "        if col in game.columns:\n",
    "            ok, msg = validate_fk(game, col, team, \"team_id\")\n",
    "            print(f\"FK fact_game.{col} -> dim_team.team_id: {ok}. {msg}\")\n",
    "if not stats.empty and not game.empty:\n",
    "    ok, msg = validate_fk(stats, \"game_id\", game, \"game_id\"); print(f\"FK fact_player_game.game_id -> fact_game.game_id: {ok}. {msg}\")\n",
    "if not stats.empty and not player.empty:\n",
    "    ok, msg = validate_fk(stats, \"player_id\", player, \"player_id\"); print(f\"FK fact_player_game.player_id -> dim_player.player_id: {ok}. {msg}\")\n",
    "\n",
    "# Ingestion automation: detect new data against previous snapshot\n",
    "status_file = os.path.join(cwd, \"data_status.csv\")\n",
    "current = {k: (dfs[k].shape[0] if k in dfs and not dfs[k].empty else 0) for k in files}\n",
    "prev = {}\n",
    "if os.path.exists(status_file):\n",
    "    try:\n",
    "        prev_df = pd.read_csv(status_file)\n",
    "        prev = dict(zip(prev_df[\"table\"], prev_df[\"rows\"]))\n",
    "    except Exception:\n",
    "        prev = {}\n",
    "\n",
    "changes = {}\n",
    "for k, n in current.items():\n",
    "    delta = n - prev.get(k, 0)\n",
    "    if delta != 0:\n",
    "        changes[k] = delta\n",
    "\n",
    "if changes:\n",
    "    print(\"Ingestion changes detected since last run:\")\n",
    "    for k, d in changes.items():\n",
    "        sign = \"+\" if d >= 0 else \"\"\n",
    "        print(f\"{k}: {sign}{d} rows vs previous run\")\n",
    "else:\n",
    "    print(\"No ingestion changes detected since last run\")\n",
    "\n",
    "# Persist snapshot for next executions\n",
    "pd.DataFrame({\"table\": list(current.keys()), \"rows\": list(current.values())}).to_csv(status_file, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"Saved ingestion status snapshot to {status_file}\")\n",
    "\n",
    "# Generate SQL Server DDL\n",
    "ddl_sqlserver = '''\n",
    "-- NBA Star Schema for SQL Server\n",
    "CREATE TABLE dim_team (\n",
    "    team_id INT PRIMARY KEY,\n",
    "    full_name NVARCHAR(100) NULL,\n",
    "    abbreviation NVARCHAR(10) NULL,\n",
    "    nickname NVARCHAR(50) NULL,\n",
    "    city NVARCHAR(50) NULL,\n",
    "    state NVARCHAR(50) NULL\n",
    ");\n",
    "CREATE TABLE dim_player (\n",
    "    player_id INT PRIMARY KEY,\n",
    "    full_name NVARCHAR(100) NULL,\n",
    "    position NVARCHAR(20) NULL,\n",
    "    height_cm FLOAT NULL,\n",
    "    weight_kg FLOAT NULL,\n",
    "    nationality NVARCHAR(50) NULL\n",
    ");\n",
    "CREATE TABLE fact_game (\n",
    "    game_id INT PRIMARY KEY,\n",
    "    game_date_est DATE NULL,\n",
    "    season INT NULL,\n",
    "    home_team_id INT NULL,\n",
    "    visitor_team_id INT NULL,\n",
    "    game_status_id INT NULL,\n",
    "    FOREIGN KEY (home_team_id) REFERENCES dim_team(team_id),\n",
    "    FOREIGN KEY (visitor_team_id) REFERENCES dim_team(team_id)\n",
    ");\n",
    "CREATE TABLE fact_player_game (\n",
    "    game_id INT NOT NULL,\n",
    "    player_id INT NOT NULL,\n",
    "    team_id INT NULL,\n",
    "    season INT NULL,\n",
    "    points FLOAT NULL,\n",
    "    assists FLOAT NULL,\n",
    "    rebounds FLOAT NULL,\n",
    "    minutes_played FLOAT NULL,\n",
    "    PRIMARY KEY (game_id, player_id),\n",
    "    FOREIGN KEY (game_id) REFERENCES fact_game(game_id),\n",
    "    FOREIGN KEY (player_id) REFERENCES dim_player(player_id)\n",
    ");\n",
    "'''\n",
    "ddl_path = os.path.join(cwd, \"nba_schema_sqlserver.sql\")\n",
    "with open(ddl_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(ddl_sqlserver)\n",
    "print(f\"Wrote SQL DDL to {ddl_path}\")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Completed FINAL processing in {end - start:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
